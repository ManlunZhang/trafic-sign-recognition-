{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%mat|plotlib` not found.\n"
     ]
    }
   ],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%mat|plotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "from fastai.metrics import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from collections import defaultdict, namedtuple\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unpack the training set and the test set\n",
    "\n",
    "! wget http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip -P data\n",
    "! wget http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Test_Images.zip -P data\n",
    "! wget http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Test_GT.zip -P data\n",
    "! unzip data/GTSRB_Final_Training_Images.zip -d data\n",
    "! unzip data/GTSRB_Final_Test_Images.zip -d data\n",
    "! unzip data/GTSRB_Final_Test_GT.zip -d data\n",
    "\n",
    "# Move the test set to data/test\n",
    "\n",
    "! mkdir data/test\n",
    "! mv data/GTSRB/Final_Test/Images/*.ppm data/test\n",
    "\n",
    "# Download class names\n",
    "! wget https://raw.githubusercontent.com/georgesung/traffic_sign_classification_german/master/signnames.csv -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotation = namedtuple('Annotation', ['filename', 'label'])\n",
    "def read_annotations(filename):\n",
    "    annotations = []\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f, delimiter=';')\n",
    "        next(reader) # skip header\n",
    "\n",
    "        # loop over all images in current annotations file\n",
    "        for row in reader:\n",
    "            filename = row[0] # filename is in the 0th column\n",
    "            label = int(row[7]) # label is in the 7th column\n",
    "            annotations.append(Annotation(filename, label))\n",
    "            \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_annotations(source_path):\n",
    "    annotations = []\n",
    "    for c in range(0,43):\n",
    "        filename = os.path.join(source_path, format(c, '05d'), 'GT-' + format(c, '05d') + '.csv')\n",
    "        annotations.extend(read_annotations(filename))\n",
    "    return annotations\n",
    "\n",
    "def copy_files(label, filenames, source, destination, move=False):\n",
    "    func = os.rename if move else shutil.copyfile\n",
    "    \n",
    "    label_path = os.path.join(destination, str(label))\n",
    "    if not os.path.exists(label_path):\n",
    "        os.makedirs(label_path)\n",
    "        \n",
    "    for filename in filenames:\n",
    "        destination_path = os.path.join(label_path, filename)\n",
    "        if not os.path.exists(destination_path):\n",
    "            func(os.path.join(source, format(label, '05d'), filename), destination_path)\n",
    "\n",
    "def split_train_validation_sets(source_path, train_path, validation_path, all_path, validation_fraction=0.2):\n",
    "    \"\"\"\n",
    "    Splits the GTSRB training set into training and validation sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path)\n",
    "        \n",
    "    if not os.path.exists(validation_path):\n",
    "        os.makedirs(validation_path)\n",
    "        \n",
    "    if not os.path.exists(all_path):\n",
    "        os.makedirs(all_path)\n",
    "    \n",
    "    annotations = load_training_annotations(source_path)\n",
    "    filenames = defaultdict(list)\n",
    "    for annotation in annotations:\n",
    "        filenames[annotation.label].append(annotation.filename)\n",
    "\n",
    "    for label, filenames in filenames.items():\n",
    "        filenames = sorted(filenames)\n",
    "        \n",
    "        validation_size = int(len(filenames) // 30 * validation_fraction) * 30\n",
    "        train_filenames = filenames[validation_size:]\n",
    "        validation_filenames = filenames[:validation_size]\n",
    "        \n",
    "        copy_files(label, filenames, source_path, all_path, move=False)\n",
    "        copy_files(label, train_filenames, source_path, train_path, move=True)\n",
    "        copy_files(label, validation_filenames, source_path, validation_path, move=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "source_path = os.path.join(path, 'GTSRB/Final_Training/Images')\n",
    "train_path = os.path.join(path, 'train')\n",
    "validation_path = os.path.join(path, 'valid')\n",
    "all_path = os.path.join(path, 'all')\n",
    "validation_fraction = 0.2\n",
    "split_train_validation_sets(source_path, train_path, validation_path, all_path, validation_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotations = read_annotations('data/GT-final_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_csv('data/signnames.csv')\n",
    "class_names = {}\n",
    "for i, row in classes.iterrows():\n",
    "    class_names[str(row[0])] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch=resnet34\n",
    "sz = 96\n",
    "data = ImageClassifierData.from_paths(path, tfms=tfms_from_model(arch, sz), test_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(load_img_id(data.val_ds, 1, path))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.trn_ds.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(y).most_common()\n",
    "for l, c in label_counts:\n",
    "    print(c, '\\t', data.classes[l], '\\t', class_names[data.classes[l]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in sorted([l for l, c in label_counts], key=lambda p: int(data.classes[p])):\n",
    "    i = [i for i, l in enumerate(y) if l == label][0]\n",
    "    print(data.classes[y[i]], class_names[data.classes[y[i]]])\n",
    "    plt.imshow(load_img_id(data.trn_ds, i, path))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n",
    "\n",
    "folder = 'data/all/0'\n",
    "\n",
    "files = os.listdir(folder)\n",
    "sizes = []\n",
    "\n",
    "for file in files:\n",
    "    filename = os.path.join(folder, file)\n",
    "    img = cv2.imread(filename, flags)\n",
    "    sizes.append(max(img.shape[0], img.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sizes, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image lighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try histogram equalization to improve constrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n",
    "\n",
    "folder = 'data/all/0'\n",
    "\n",
    "files = os.listdir(folder)\n",
    "for i in range(5):\n",
    "    f = plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    filename = os.path.join(folder, files[i])\n",
    "    img = cv2.imread(filename, flags)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    sp = f.add_subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    img = np.concatenate([np.expand_dims(cv2.equalizeHist(img[:,:,i]), axis=2) for i in range(3)], axis=2)\n",
    "    \n",
    "    \n",
    "    sp = f.add_subplot(1, 2, 2)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal version\n",
    "\n",
    "def open_image_normal(fn):\n",
    "    \"\"\" Opens an image using OpenCV given the file path.\n",
    "\n",
    "    Arguments:\n",
    "        fn: the file path of the image\n",
    "\n",
    "    Returns:\n",
    "        The numpy array representation of the image in the RGB format\n",
    "    \"\"\"\n",
    "    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n",
    "    if not os.path.exists(fn):\n",
    "        raise OSError('No such file or directory: {}'.format(fn))\n",
    "    elif os.path.isdir(fn):\n",
    "        raise OSError('Is a directory: {}'.format(fn))\n",
    "    else:\n",
    "        try:\n",
    "            return cv2.cvtColor(cv2.imread(fn, flags), cv2.COLOR_BGR2RGB).astype(np.float32)/255\n",
    "        except Exception as e:\n",
    "            raise OSError('Error handling image at: {}'.format(fn)) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization\n",
    "\n",
    "def open_image_hist_eq(fn):\n",
    "    \"\"\" Opens an image using OpenCV given the file path.\n",
    "\n",
    "    Arguments:\n",
    "        fn: the file path of the image\n",
    "\n",
    "    Returns:\n",
    "        The numpy array representation of the image in the RGB format\n",
    "    \"\"\"\n",
    "    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n",
    "    if not os.path.exists(fn):\n",
    "        raise OSError('No such file or directory: {}'.format(fn))\n",
    "    elif os.path.isdir(fn):\n",
    "        raise OSError('Is a directory: {}'.format(fn))\n",
    "    else:\n",
    "        try:\n",
    "            img = cv2.cvtColor(cv2.imread(fn, flags), cv2.COLOR_BGR2RGB)\n",
    "            img = np.concatenate([np.expand_dims(cv2.equalizeHist(img[:,:,i]), axis=2) for i in range(3)], axis=2)\n",
    "            return img.astype(np.float32)/255\n",
    "        except Exception as e:\n",
    "            raise OSError('Error handling image at: {}'.format(fn)) from e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the 2nd line below to apply histogram equalization to fastai dataset code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_image = open_image_normal\n",
    "#open_image = open_image_hist_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a bug in fastai: augmented training set images are not shuffled.\n",
    "We have to fix it here by redefining ImageData class. We also need to redefine ImageClassifierData because it uses ImageData.\n",
    "I'll make a pull request to fix it in the library later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageData(ModelData):\n",
    "    def __init__(self, path, datasets, bs, num_workers, classes):\n",
    "        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n",
    "        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n",
    "        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n",
    "            self.get_dl(ds,shuf) for ds,shuf in [\n",
    "                (trn_ds,True),(val_ds,False),(fix_ds,False),(aug_ds,True),\n",
    "                (test_ds,False),(test_aug_ds,False)\n",
    "            ]\n",
    "        ]\n",
    "        print('augmentated training samples are shuffled')\n",
    "\n",
    "    def get_dl(self, ds, shuffle):\n",
    "        if ds is None: return None\n",
    "        return ModelDataLoader.create_dl(ds, batch_size=self.bs, shuffle=shuffle,\n",
    "            num_workers=self.num_workers, pin_memory=False)\n",
    "\n",
    "    @property\n",
    "    def sz(self): return self.trn_ds.sz\n",
    "    @property\n",
    "    def c(self): return self.trn_ds.c\n",
    "\n",
    "    def resized(self, dl, targ, new_path):\n",
    "        return dl.dataset.resize_imgs(targ,new_path) if dl else None\n",
    "\n",
    "    def resize(self, targ, new_path):\n",
    "        new_ds = []\n",
    "        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n",
    "        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n",
    "        else: dls += [None,None]\n",
    "        t = tqdm_notebook(dls)\n",
    "        for dl in t: new_ds.append(self.resized(dl, targ, new_path))\n",
    "        t.close()\n",
    "        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifierData(ImageData):\n",
    "    @property\n",
    "    def is_multi(self): return self.trn_dl.dataset.is_multi\n",
    "\n",
    "    @staticmethod\n",
    "    def get_ds(fn, trn, val, tfms, test=None, **kwargs):\n",
    "        res = [\n",
    "            fn(trn[0], trn[1], tfms[0], **kwargs), # train\n",
    "            fn(val[0], val[1], tfms[1], **kwargs), # val\n",
    "            fn(trn[0], trn[1], tfms[1], **kwargs), # fix\n",
    "            fn(val[0], val[1], tfms[0], **kwargs)  # aug\n",
    "        ]\n",
    "        if test is not None:\n",
    "            test_lbls = np.zeros((len(test),1))\n",
    "            res += [\n",
    "                fn(test, test_lbls, tfms[1], **kwargs), # test\n",
    "                fn(test, test_lbls, tfms[0], **kwargs)  # test_aug\n",
    "            ]\n",
    "        else: res += [None,None]\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def from_arrays(cls, path, trn, val, bs=64, tfms=(None,None), classes=None, num_workers=4, test=None):\n",
    "        \"\"\" Read in images and their labels given as numpy arrays\n",
    "\n",
    "        Arguments:\n",
    "            path: a root path of the data (used for storing trained models, precomputed values, etc)\n",
    "            trn: a tuple of training data matrix and target label/classification array (e.g. `trn=(x,y)` where `x` has the\n",
    "                shape of `(5000, 784)` and `y` has the shape of `(5000,)`)\n",
    "            val: a tuple of validation data matrix and target label/classification array.\n",
    "            bs: batch size\n",
    "            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n",
    "            classes: a list of all labels/classifications\n",
    "            num_workers: a number of workers\n",
    "            test: a matrix of test data (the shape should match `trn[0]`)\n",
    "\n",
    "        Returns:\n",
    "            ImageClassifierData\n",
    "        \"\"\"\n",
    "        datasets = cls.get_ds(ArraysIndexDataset, trn, val, tfms, test=test)\n",
    "        return cls(path, datasets, bs, num_workers, classes=classes)\n",
    "\n",
    "    @classmethod\n",
    "    def from_paths(cls, path, bs=64, tfms=(None,None), trn_name='train', val_name='valid', test_name=None, num_workers=8):\n",
    "        \"\"\" Read in images and their labels given as sub-folder names\n",
    "\n",
    "        Arguments:\n",
    "            path: a root path of the data (used for storing trained models, precomputed values, etc)\n",
    "            bs: batch size\n",
    "            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n",
    "            trn_name: a name of the folder that contains training images.\n",
    "            val_name:  a name of the folder that contains validation images.\n",
    "            test_name:  a name of the folder that contains test images.\n",
    "            num_workers: number of workers\n",
    "\n",
    "        Returns:\n",
    "            ImageClassifierData\n",
    "        \"\"\"\n",
    "        trn,val = [folder_source(path, o) for o in (trn_name, val_name)]\n",
    "        test_fnames = read_dir(path, test_name) if test_name else None\n",
    "        datasets = cls.get_ds(FilesIndexArrayDataset, trn, val, tfms, path=path, test=test_fnames)\n",
    "        return cls(path, datasets, bs, num_workers, classes=trn[2])\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(cls, path, folder, csv_fname, bs=64, tfms=(None,None),\n",
    "               val_idxs=None, suffix='', test_name=None, continuous=False, skip_header=True, num_workers=8):\n",
    "        \"\"\" Read in images and their labels given as a CSV file.\n",
    "\n",
    "        This method should be used when training image labels are given in an CSV file as opposed to\n",
    "        sub-directories with label names.\n",
    "\n",
    "        Arguments:\n",
    "            path: a root path of the data (used for storing trained models, precomputed values, etc)\n",
    "            folder: a name of the folder in which training images are contained.\n",
    "            csv_fname: a name of the CSV file which contains target labels.\n",
    "            bs: batch size\n",
    "            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n",
    "            val_idxs: index of images to be used for validation. e.g. output of `get_cv_idxs`.\n",
    "                If None, default arguments to get_cv_idxs are used.\n",
    "            suffix: suffix to add to image names in CSV file (sometimes CSV only contains the file name without file\n",
    "                    extension e.g. '.jpg' - in which case, you can set suffix as '.jpg')\n",
    "            test_name: a name of the folder which contains test images.\n",
    "            continuous: TODO\n",
    "            skip_header: skip the first row of the CSV file.\n",
    "            num_workers: number of workers\n",
    "\n",
    "        Returns:\n",
    "            ImageClassifierData\n",
    "        \"\"\"\n",
    "        fnames,y,classes = csv_source(folder, csv_fname, skip_header, suffix, continuous=continuous)\n",
    "\n",
    "        val_idxs = get_cv_idxs(len(fnames)) if val_idxs is None else val_idxs\n",
    "        ((val_fnames,trn_fnames),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), y)\n",
    "\n",
    "        test_fnames = read_dir(path, test_name) if test_name else None\n",
    "        if continuous:\n",
    "            f = FilesIndexArrayRegressionDataset\n",
    "        else:\n",
    "            f = FilesIndexArrayDataset if len(trn_y.shape)==1 else FilesNhotArrayDataset\n",
    "        datasets = cls.get_ds(f, (trn_fnames,trn_y), (val_fnames,val_y), tfms,\n",
    "                               path=path, test=test_fnames)\n",
    "        return cls(path, datasets, bs, num_workers, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can change image augmentation parameters and see how augmented images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at examples of image augmentation\n",
    "def get_augs():\n",
    "    x,_ = next(iter(data.aug_dl))\n",
    "    return data.trn_ds.denorm(x)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs = 256\n",
    "\n",
    "aug_tfms = [RandomRotate(20), RandomLighting(0.8, 0.8)]\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=aug_tfms, max_zoom=1.2)\n",
    "data = ImageClassifierData.from_paths(path, tfms=tfms, test_name='test', bs=bs)\n",
    "\n",
    "ims = np.stack([get_augs() for i in range(6)])\n",
    "plots(ims, rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a learner\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for a good starting learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_change(sched, sma=1, n_skip=20, y_lim=(-0.01,0.01)):\n",
    "    \"\"\"\n",
    "    Plots rate of change of the loss function.\n",
    "    Parameters:\n",
    "        sched - learning rate scheduler, an instance of LR_Finder class.\n",
    "        sma - number of batches for simple moving average to smooth out the curve.\n",
    "        n_skip - number of batches to skip on the left.\n",
    "        y_lim - limits for the y axis.\n",
    "    \"\"\"\n",
    "    derivatives = [0] * (sma + 1)\n",
    "    for i in range(1 + sma, len(learn.sched.lrs)):\n",
    "        derivative = (learn.sched.losses[i] - learn.sched.losses[i - sma]) / sma\n",
    "        derivatives.append(derivative)\n",
    "        \n",
    "    plt.ylabel(\"d/loss\")\n",
    "    plt.xlabel(\"learning rate (log scale)\")\n",
    "    plt.plot(learn.sched.lrs[n_skip:], derivatives[n_skip:])\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_change(learn.sched, sma=20, n_skip=20, y_lim=(-0.02, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with LR 0.01 for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(0.01, 1, wds=wd)\n",
    "#learn.fit(0.01, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_change(learn.sched, sma=20, n_skip=20, y_lim=(-0.02, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze and train with LR 0.01 for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit(0.01, 3, wds=wd)\n",
    "#learn.fit(0.01, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_change(learn.sched, sma=20, n_skip=20, y_lim=(-0.01, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train for a few cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 4, cycle_len=1, cycle_mult=2, wds=wd)\n",
    "#learn.fit(lr, 4, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_loss_change(learn.sched, sma=20, n_skip=20, y_lim=(-0.02, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_preds,y = learn.predict_with_targs()\n",
    "preds = np.exp(log_preds)\n",
    "pred_labels = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ImageModelResults(data.val_ds, log_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = [i for i in range(len(pred_labels)) if pred_labels[i] != y[i]]\n",
    "c = Counter([(y[i], class_names[data.classes[y[i]]]) for i in incorrect])\n",
    "c.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results.plot_most_incorrect(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_most_incorrect(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.plot_most_incorrect(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_most_correct(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_most_correct(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.plot_most_correct(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_most_uncertain(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test time augmentation (TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds,y = learn.TTA(n_aug=20)\n",
    "preds = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_np(preds, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain on the training set + validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss/accuracy won't be indicative of the model performance because the validation set is a subset of the training set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnet34\n",
    "sz = 96\n",
    "bs = 256\n",
    "wd = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms = [RandomRotate(20), RandomLighting(0.8, 0.8)]\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=aug_tfms, max_zoom=1.2)\n",
    "data = ImageClassifierData.from_paths(path, tfms=tfms, trn_name='all', val_name='valid', test_name='test', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit(lr, 3, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 4, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test_labels = {a.filename: a.label for a in test_annotations}\n",
    "class_indexes = {c: i for i, c in enumerate(data.classes)}\n",
    "filenames = [filepath[filepath.find('/') + 1:] for filepath in data.test_ds.fnames]\n",
    "labels = [str(true_test_labels[filename]) for filename in filenames]\n",
    "y_true = np.array([class_indexes[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds = learn.predict(is_test=True)\n",
    "preds = np.exp(log_preds)\n",
    "accuracy_np(preds, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds,_ = learn.TTA(n_aug=20, is_test=True)\n",
    "preds = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(preds, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = [i for i in range(len(pred_labels)) if pred_labels[i] != y_true[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    print(class_names[data.classes[y_true[incorrect[i]]]], class_names[data.classes[pred_labels[incorrect[i]]]], \n",
    "          preds[incorrect[i], y_true[incorrect[i]]], preds[incorrect[i], pred_labels[incorrect[i]]])\n",
    "    plt.imshow(load_img_id(data.test_ds, incorrect[i], path))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(path, 'confusion_matrix.tsv'), cm, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = Counter([class_names[data.classes[y_true[i]]] for i in incorrect])\n",
    "c.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter([class_names[data.classes[pred_labels[i]]] for i in incorrect])\n",
    "c.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(preds, axis=1)\n",
    "pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    class_id = data.classes[pred_labels[i]]\n",
    "    filename = data.test_ds.fnames[i].split('/')[1]\n",
    "    print(filename, class_id, class_names[class_id])\n",
    "    plt.imshow(load_img_id(data.test_ds, i, path))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/submission.csv', 'w') as f:\n",
    "    for i in range(pred_labels.shape[0]):\n",
    "        filename = data.test_ds.fnames[i].split('/')[1]\n",
    "        f.write('{};{}\\n'.format(filename, data.classes[pred_labels[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
